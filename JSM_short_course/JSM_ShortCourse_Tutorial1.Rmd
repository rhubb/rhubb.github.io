---
title: "Practical solutions for working with electronic health records data"
output:
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  

***

#### Introduction

The goal of this tutorial is to explore the structure of an electronic health records (EHR)-derived data set and some of the common challenges encountered in working with healthcare-derived data. We will also practice implementing some statistical methods introduced throughout the tutorial to address these issues. To do this we will use a synthetic data set simulated to mimic the structure of a real EHR-derived data set. **Please note that the data we will be working with are simulated and intended for instructional purposes only.** Real EHR data generally have access restrictions due to privacy/confidentiality issues and HIPAA protections. At the end of the course we will provide links for a few public access repositories that provide real EHR data. However, these generally do require a data use agreement and thus a few steps are involved in getting access.

The synthetic data we will be working with are based on the PEDSnet study of pediatric type 2 diabetes described in class. The data are divided into four files which can be downloaded from GitHub. The four files contain data from 9,930 patients age 10-20 years who had at least one outpatient encounter between 2001 and 2019. The four files can be linked using the variable patientid.

#### Encounter data
This data set includes one row per outpatient encounter. 
```{r, eval = TRUE, echo = TRUE}
encounter = read.csv("https://raw.githubusercontent.com/rhubb/rhubb.github.io/master/data/encounter.csv", head=T)
```
<blockquote style="font-size:12px">
patientid:  Patient ID

servicedate: Date of the encounter

age:  Age in years

race: Provider-reported patient race

proc:  CPT codes for procedure performed; codes 99211-99215 are for evaluation and management of established patients in an outpatient setting

diag: ICD-9 (before 10/1/2015) or ICD-10 (on or after 10/1/2015) for primary diagnosis; a few diagnosis codes of interest are T2DM ICD-9 = "250.00"; T2DM ICD-10 = "E11.9"; T1DM ICD-9 = "250.01"; T1DM ICD-10 = "E10.9"; Depression ICD-9 = "296.2","296.9","296.3","300.4"; Depression ICD-10 = "F32.9","F41.8","F33.9"

prov: CMS provider specialty code; a few provider codes of potential interest are General Practice = "1", General Dermatology = "7", Family practice = "8", Internal Medicine = "11", Neurology = "13", Ophthalmology = "18", Psychiatry = "26", Pediatric Medicine = "37", Endocrinology = "46"

</blockquote>

#### Prescription medication data
This data set includes one row per prescription recorded on the date of an outpatient encounter included in the encounters file. 
```{r, eval = TRUE, echo = TRUE}
meds = read.csv("https://raw.githubusercontent.com/rhubb/rhubb.github.io/master/data/meds.csv", head=T)
```

<blockquote style="font-size:12px">
patientid:  Patient ID

presdate: Date of the prescription

drug:  Drug class

</blockquote>

#### Measures data
This data set includes one row per anthropometric or laboratory measurement recorded on the date of an outpatient encounter included in the encounters file. 
```{r, eval = TRUE, echo = TRUE}
measures = read.csv("https://raw.githubusercontent.com/rhubb/rhubb.github.io/master/data/measures.csv", head=T)
```

<blockquote style="font-size:12px">
patientid:  Patient ID

servicedate: Date of measurement

measurement: Numeric value of the measurement

measuretype: Description of the laboratory or anthropometric test (height in cm, weight in kg, glucose in mg/dl, hemoglobin A1c (hba1c) in \%, cholesterol (chol) in mg/dl)

</blockquote>

#### Validation data
This data set includes one row per patient for 998 patients randomly selected for manual chart review to determine gold-standard type 2 diabetes status. 
```{r, eval = TRUE, echo = TRUE}
validation = read.csv("https://raw.githubusercontent.com/rhubb/rhubb.github.io/master/data/validation.csv", head=T)
```

<blockquote style="font-size:12px">
patientid:  Patient ID

T2DMv: Type 2 diabetes status based on manual chart review (1 = T2DM, 0 = no evidence of T2DM)

</blockquote>

#### Install R packages
- For these exercises you will need the [_rpart_](https://cran.r-project.org/web/packages/rpart/index.html), [_pROC_](https://cran.r-project.org/web/packages/pROC/index.html), [_boot_](https://cran.r-project.org/web/packages/boot/index.html), and [_gee_](https://cran.r-project.org/web/packages/gee/index.html) packages.
- If you have not already, please install these packages now.
```{r, eval=FALSE}
install.packages("rpart")
install.packages("pROC")
install.packages("boot")
install.packages("gee")
library(rpart)
library(pROC)
library(boot)
library(gee)
```
```{r, eval=TRUE, message = FALSE, echo = FALSE}
library(rpart)
library(pROC)
library(boot)
library(gee)
```

### Tutorial 1

A\. **Data Quality Evaluation.** The first task in analysis of EHR data is data exploration and visualization to identify and resolve data errors. Focusing on the measures data set, we will carry out a descriptive analysis. 

* Are there any observations that seem likely to be errors? 
* What are some techniques we can use to identify errors? 
* What are some options for handling possibly erroneous data points once they have been identified?
```{r, eval = TRUE, echo = TRUE, cache = FALSE, cache.lazy = FALSE}
## Use summary statistics and plots to investigate basic characteristics of the data

summary(measures)

# check types of measures available
unique(measures$measuretype)

# separate variables by measurement type
height <- measures[measures$measuretype == "height",-4]
names(height) <- c("patientid","servicedate","height")

weight <- measures[measures$measuretype == "weight",-4]
names(weight) <- c("patientid","servicedate","weight")

glucose <- measures[measures$measuretype == "glucose",-4]
names(glucose) <- c("patientid","servicedate","glucose")

hba1c <- measures[measures$measuretype == "hba1c",-4]
names(hba1c) <- c("patientid","servicedate","hba1c")

chol <- measures[measures$measuretype == "chol",-4]
names(chol) <- c("patientid","servicedate","chol")

# explore number of observations available per patient for each measurement type

summary(c(table(factor(height$patientid, levels = unique(encounter$patientid)))))
summary(c(table(factor(weight$patientid, levels = unique(encounter$patientid)))))
summary(c(table(factor(glucose$patientid, levels = unique(encounter$patientid)))))
summary(c(table(factor(hba1c$patientid, levels = unique(encounter$patientid)))))
summary(c(table(factor(chol$patientid, levels = unique(encounter$patientid)))))

# number of children with no measures available

sum(c(table(factor(height$patientid, levels = unique(encounter$patientid)))) == 0)
sum(c(table(factor(weight$patientid, levels = unique(encounter$patientid)))) == 0)
sum(c(table(factor(glucose$patientid, levels = unique(encounter$patientid)))) == 0)
sum(c(table(factor(hba1c$patientid, levels = unique(encounter$patientid)))) == 0)
sum(c(table(factor(chol$patientid, levels = unique(encounter$patientid)))) == 0)

# summarize distribution of variables across all patients, looking for values outside the plausible range

summary(height$height)
summary(weight$weight)
summary(glucose$glucose)
summary(hba1c$hba1c)
summary(chol$chol)

# values that are clearly outside the plausible range can be eliminated, those that seem unlikely should be
# noted for discussion with clinical collaborators

# remove negative weights as clearly lying outside the plausible range

weight$weight <- ifelse(weight$weight < 0, NA, weight$weight)

# identify patients with extreme heights and weights

extreme.heights <- height$patientid[height$height < 100] # flag patients with height < 1 m
extreme.weights <- weight$patientid[weight$weight > 200] # flag patients with weight > 200 kg

# implausible patterns in longitudinal measurements provide an additional means of identifying data errors

height.s <- split(data.frame(height$servicedate,height$height),height$patientid)
weight.s <- split(data.frame(as.Date(weight$servicedate),weight$weight),weight$patientid)
glucose.s <- split(data.frame(as.Date(glucose$servicedate),glucose$glucose),glucose$patientid)
hba1c.s <- split(data.frame(as.Date(hba1c$servicedate),hba1c$hba1c),hba1c$patientid)

# summarize rate of change and within-patient variability

# function to estimate rate of change and residual variability for each child's data
longrate <- function(x){
  days <- as.numeric(as.Date(x[,1]))
  measure <- x[,2]
  mod <- lm(measure ~ days)
  rate <- mod$coef[2]
  residsd <- summary(mod)$sigma
  return(c(rate,residsd))
}

height.lm <- t(sapply(height.s,longrate))

# take a look at a few patients with implausible trajectories

height.change.ind <- which(abs(height.lm[,1]) > 0.5)     
par(mfrow = c(2,3))
for (i in 1:6){
  plot(as.numeric(as.Date(height.s[[height.change.ind[i]]][,1])),height.s[[height.change.ind[i]]][,2], xlab = "date", ylab = "height", type = "l")
}

# a few of these measures look very suspicious, as if one measurement is about 2.5 times the other
# take a closer look at an example case

height[height$patientid == names(height.change.ind[4]),]

# generate BMI and look for implausible values

height$iddate <- paste(height$patientid,height$servicedate)
weight$iddate <- paste(weight$patientid,weight$servicedate)
bmi <- merge(height,weight,by = "iddate") # merge height and weight data 
bmi$bmi <- bmi$weight/(bmi$height/100)^2

par(mfrow = c(2,2))
hist(bmi$bmi)
plot(bmi$weight,bmi$bmi)
plot(bmi$height,bmi$bmi)

# unusual groupings in BMI plots suggest patients with wrong units for height or weight
# select a rule for eliminating these heights or weights

bmi$height <- ifelse(bmi$height < 100 & bmi$bmi > 100, bmi$height*2.54, bmi$height)
bmi$bmi <- bmi$weight/(bmi$height/100)^2

par(mfrow = c(2,2))
hist(bmi$bmi)
plot(bmi$weight,bmi$bmi)
plot(bmi$height,bmi$bmi)

```

B\. **Phenotype Extraction.** We will next explore a few alternative approaches to deriving a type 2 diabetes (T2DM) phenotype from this data set. 

* Reduce the data to one observation per patient considering what data elements might be of use at the patient-level. 
* Use the validation data to develop a prediction model for T2DM using logistic regression and CART. 
* Apply the eMERGE T2DM rule to these data. How do the sensitivity, specificity, PPV, and NPV of these approaches compare?
```{r, eval = TRUE, echo = TRUE, cache = FALSE, cache.lazy = FALSE}
## Aggregate data to the patient level

# aggregate numeric measurements using the earliest, mean and maximum observed values

bmi$bmimean <- unsplit(sapply(split(bmi$bmi,bmi$patientid.x),mean,na.rm = T),bmi$patientid.x)
bmi$bmimax <- unsplit(sapply(split(bmi$bmi,bmi$patientid.x),max,na.rm = T),bmi$patientid.x)
bmi$firstbmi <- unsplit(sapply(split(bmi$bmi,bmi$patientid.x),function(x){x[1]}),bmi$patientid.x)

glucose$glucosemean <- unsplit(sapply(split(glucose$glucose,glucose$patientid),mean,na.rm = T),glucose$patientid)
glucose$glucosemax <- unsplit(sapply(split(glucose$glucose,glucose$patientid),max,na.rm = T),glucose$patientid)

hba1c$hba1cmean <- unsplit(sapply(split(hba1c$hba1c,hba1c$patientid),mean,na.rm = T),hba1c$patientid)
hba1c$hba1cmax <- unsplit(sapply(split(hba1c$hba1c,hba1c$patientid),max,na.rm = T),hba1c$patientid)

encounter$agemean <- unsplit(sapply(split(encounter$age,encounter$patientid),mean,na.rm = T),encounter$patientid)
encounter$firstage <- unsplit(sapply(split(encounter$age,encounter$patientid),min,na.rm = T),encounter$patientid)

# compute elapsed time from first visit to current visit and summarize cholesterol in first year of follow-up
encounter$basedate <- rep(encounter$servicedate[!duplicated(encounter$patientid)], time = c(table(encounter$patientid))) # date of first visit
encounter$elapsed <- as.Date(encounter$servicedate) - as.Date(encounter$basedate)
encounter$anyvisit1yr <- unsplit(sapply(split(encounter$elapsed,encounter$patientid), # binary indicator of any visit in first year of follow-up
                                   function(x){sum(x[x>0] <= 365) > 0}),encounter$patientid)
chol <- merge(chol,data.frame(patientid = encounter$patientid, basedate = encounter$basedate)[!duplicated(encounter$patientid),], 
                              all.x = TRUE, all.y = FALSE)
chol$elapsed <- as.Date(chol$servicedate) - as.Date(chol$basedate)
chol$cholmean1yr <- unsplit(sapply(split(data.frame(chol = chol$chol, days = chol$elapsed),chol$patientid),
                                   function(x){mean(x$chol[x$days <= 365 & x$days > 0],na.rm = T)}),chol$patientid)

# look for any occurence of diabetes diagnosis codes, insulin, metformin,
# or visit to an endocrinologist within the period of interest
# T2DM ICD-9 = "250.00", T2DM ICD-10 = "E11.9", T1DM ICD-9 = "250.01", T1DM ICD-10 = "E10.9"
# Endocrinologist Medicare specialty code = 46

anycode <- function(x,code){
  code.present <- x %in% code
  return(sum(code.present)>0)
}

# Count number of occurences of code

sumcode <- function(x,code){
  code.present <- x %in% code
  return(sum(code.present))
}

# Determine whether metformin prescription precedes insulin prescription
# Returns 1 if only metformin prescribed or metformin prescribed before insulin
# otherwise returns 0

codeorder <- function(x){
  metdates <- as.Date(x$dates[x$drugs == "metformin"])
  insdates <- as.Date(x$dates[x$drugs == "insulin"])
  if (length(metdates) == 0) metfirst <- 0
  else if (length(metdates) > 0 & length(insdates) == 0) metfirst <- 1
  else if (length(metdates) == 0 & length(insdates) == 0) metfirst <- 0
  else metfirst <- suppressMessages(1*(min(metdates) < min(insdates)))
  return(metfirst)
}

# any T2DM code
encounter$T2DM <- unsplit(sapply(split(encounter$diag,encounter$patientid),anycode,code = c("250.00","E11.9")),encounter$patientid)

# number of T2DM codes
encounter$T2DMnum <- unsplit(sapply(split(encounter$diag,encounter$patientid),sumcode,code = c("250.00","E11.9")),encounter$patientid) # number of occurence of T2DM code

# any T1DM code
encounter$T1DM <- unsplit(sapply(split(encounter$diag,encounter$patientid),anycode,code = c("250.01","E10.9")),encounter$patientid)

# any visit to an endocrinologist
encounter$endo <- unsplit(sapply(split(encounter$prov,encounter$patientid),anycode,code = "46"),encounter$patientid)

# any depression diagnosis
encounter$dep <- unsplit(sapply(split(encounter$diag,encounter$patientid),anycode,code = c("296.2","296.9","296.3","300.4","F32.9","F41.8","F33.9")),encounter$patientid)

# any insulin prescription
meds$anyinsulin <- unsplit(sapply(split(meds$drug,meds$patientid),anycode,code = "insulin"),meds$patientid)

# any metformin prescription
meds$anymetformin <- unsplit(sapply(split(meds$drug,meds$patientid),anycode,code = "metformin"),meds$patientid)

# metformin prescription precedes insulin prescription
meds$metforminfirst <- unsplit(sapply(split(data.frame(dates=meds$presdate,drugs=meds$drug),
                       meds$patientid),codeorder),meds$patientid)


## Create merged dataset with one observation per patient and aggregate variables

encounter1 <- encounter[!duplicated(encounter$patientid),c("patientid","agemean","firstage","race","gender","T2DM","T1DM","endo","T2DMnum","dep","anyvisit1yr")]
bmi1 <- bmi[!duplicated(bmi$patientid.x),c("patientid.x","bmimean","bmimax","firstbmi")]
names(bmi1) <- c("patientid","bmimean","bmimax","firstbmi")
glucose1 <- glucose[!duplicated(glucose$patientid),c("patientid","glucosemean","glucosemax")]
hba1c1 <- hba1c[!duplicated(hba1c$patientid),c("patientid","hba1cmean","hba1cmax")]
chol1 <- chol[!duplicated(chol$patientid),c("patientid","cholmean1yr")]
meds1  <- meds[!duplicated(meds$patientid),c("patientid","anyinsulin","anymetformin","metforminfirst")]

data1 <- Reduce(function(x,y){merge(x,y, all = T)},list(encounter1,bmi1,glucose1,hba1c1,chol1,meds1,validation))

# create indicators for availability of any glucose or HbA1c measures

data1$anyglucose <- !is.na(data1$glucosemean)
data1$anyhba1c   <- !is.na(data1$hba1cmean)

# set insulin and metformin to false for patients with no medication data

data1$anyinsulin <- ifelse(is.na(data1$anyinsulin),FALSE,data1$anyinsulin)
data1$anymetformin <- ifelse(is.na(data1$anymetformin),FALSE,data1$anymetformin)

## Phenotyping models using gold standard labels from validation data set to construct prediction models for T2DM

## Logistic regression

mod.glm <- glm(T2DMv ~ T2DM + T1DM + bmimean + anyglucose + anyhba1c + anyinsulin + anymetformin, data = data1, family = "binomial")

# logistic regression-based phenotype
data1$T2DMglm <- predict(mod.glm, newdata = data1)

# evaluate performance of logistic regression phenotype
pred.glm <- na.omit(data.frame(pred = data1$T2DMglm,true = data1$T2DMv))
perf.glm <- roc(pred.glm$true, pred.glm$pred, auc = TRUE, print.auc = TRUE, show.thres = TRUE)

plot(perf.glm)

# Logistic regression AUC
perf.glm$auc

## CART

set.seed(20190805)
mod.cart <- rpart(T2DMv ~ T2DM + T1DM  + bmimean + anyglucose + anyhba1c, data = data1, method = "class")
mod.pruned<- prune(mod.cart, cp= mod.cart$cptable[which.min(mod.cart$cptable[,"xerror"]),"CP"])

par(xpd = NA) # prevent text labels from being cut off
plot(mod.pruned)
text(mod.pruned)

# predicted probabilities of T2DM based on CART
data1$T2DMcart <- predict(mod.pruned, newdata = data1, type = "prob")

# binary T2DM phenotype based on CART
data1$T2DMcart.class <- as.numeric(as.character(predict(mod.pruned, newdata = data1, type = "class")))

# evaluate performance of continuous CART phenotype
pred.cart <- na.omit(data.frame(pred = data1$T2DMcart[,2],true = data1$T2DMv))
perf.cart <- roc(pred.cart$true, pred.cart$pred, auc = TRUE, print.auc = TRUE, show.thres = TRUE)

par(xpd = FALSE)
plot(perf.cart)

# CART AUC
perf.cart$auc

## eMERGE T2DM rule

T2DM.rule <- function(x){
  if (x$T1DM ==1) T2DM <- 0
  else{
    if (x$T2DM ==1){
      if (x$anyinsulin == 1){
        if (x$anymetformin == 0){
          if (x$T2DMnum < 2){
            T2DM <- 0
          } else{
            T2DM <- 1
          }
        } else{
          if (x$metforminfirst == 0){
            T2DM <- 0
          } else{
            T2DM <- 1
          }
        }
      } else{
        if (x$anymetformin == 1){
          T2DM <- 1
        } else{
          if ((!is.na(x$glucosemax) & x$glucosemax > 200) | (!is.na(x$hba1cmax) & x$hba1cmax > 6.5)){
            T2DM <- 1
          } else{
            T2DM <- 0
          }
        }
      }
    } else{
      if (x$anymetformin == 0){
        T2DM <- 0
      } else{
        if ((!is.na(x$glucosemax) & x$glucosemax > 200) | (!is.na(x$hba1cmax) & x$hba1cmax > 6.5)){
          T2DM <- 1
        } else{
          T2DM <- 0
        }
      }
    }
  }
  return(T2DM)
}

data1$T2DMemerge <- unsplit(sapply(split(data1,data1$patientid),T2DM.rule),data1$patientid)

# eMERGE specificity
1-mean(data1$T2DMemerge[data1$T2DMv == 0 & !is.na(data1$T2DMv)])

# eMERGE sensitivity
mean(data1$T2DMemerge[data1$T2DMv == 1 & !is.na(data1$T2DMv)])

# eMERGE PPV
mean(data1$T2DMv[data1$T2DMemerge == 1],na.rm = T)

# eMERGE NPV
1 - mean(data1$T2DMv[data1$T2DMemerge == 0],na.rm = T)
```

C\. **Missing Data.** Next we will explore missing data in an EHR-derived data set. Suppose we want to use our T2DM phenotype from exercise 2 to explore the relationship between total cholesterol and T2DM diagnosis. 

* Using mean cholesterol in the one year period after baseline as our exposure measure, how much missingness is there? 
* Is missingness related to any other factors in the data set? 
* Use IPW with a single module or multiple modules to account for missingness in your analysis of the association between total cholesterol and T2DM. 
```{r, eval = TRUE, echo = TRUE, cache = TRUE, cache.lazy = FALSE}

## For most real examples we would want to define our exposure (cholesterol) in a window around
## cohort entry. For this toy example we will use the one year period after cohort entry. 

# Percent with no cholesterol data in first year of follow-up
mean(is.na(data1$cholmean1yr))

# Percent with no visit in first year of follow-up
mean(data1$anyvisit1yr==0)

# Look for factors associated with missing cholesterol
data1$misschol <- is.na(data1$cholmean1yr)
misschol.mod <- glm(misschol ~ firstage + race + gender + firstbmi, data = data1, family = binomial)
summary(misschol.mod)

# probability of having an observed cholesterol measure based on single stage model
data1$pobschol1[!is.na(data1$firstbmi)] <- 1-predict(misschol.mod, type = "response", data = data1)

# Estimate probability of observed cholesterol using a two stage model
# first estimate probability of having any encounter within 1 yr
anyvisit.mod <- glm(anyvisit1yr ~ firstage + race + gender + firstbmi, data = data1, family = binomial)
summary(anyvisit.mod)

# probability of having an encounter
data1$pvisit1yr[!is.na(data1$firstbmi)] <- predict(anyvisit.mod, type = "response")

# next estimate probability of having cholesterol measurement given an encounter was observed
misschol.mod2 <- glm(misschol ~ firstage + race + gender + firstbmi, data = data1[data1$anyvisit1yr == 1,], family = binomial)
summary(misschol.mod2)

# probability of having a choletserol measure given an encounter occurred in first year
data1$pobschol2[!is.na(data1$firstbmi)] <- 1-predict(misschol.mod2, type = "response", newdata = data1[!is.na(data1$firstbmi),])

# create combined probability of having an observed cholesterol value using the two stage model
data1$pobschol.mod <- data1$pvisit1yr*data1$pobschol2

## Compare one module and two module probabilities of being observed
plot(data1$pobschol1, data1$pobschol.mod, xlim = c(0,0.6), ylim = c(0,0.6))
abline(0,1)

## Fit regression models using IPW to account for missingness in cholesterol

# Model using 1 step weights
data1$w1 <- 1/data1$pobschol1 # inverse probability of observed cholesterol value
data1$w1[!is.na(data1$cholmean1yr)] <- sum(!is.na(data1$cholmean1yr))*data1$w1[!is.na(data1$cholmean1yr)]/
  sum(data1$w1[!is.na(data1$cholmean1yr)],na.rm = T) # normalize weights to maintain sample size
chol.mod1 <- glm(T2DMcart.class~ firstage + factor(race) + gender + cholmean1yr, data = data1, weights = w1, family = "binomial")
summary(chol.mod1)

# Model using 2 step weights
data1$w.mod <- 1/data1$pobschol.mod # inverse probability of observed cholesterol value
data1$w.mod[!is.na(data1$cholmean1yr)] <- sum(!is.na(data1$cholmean1yr))*data1$w.mod[!is.na(data1$cholmean1yr)]/
  sum(data1$w.mod[!is.na(data1$cholmean1yr)],na.rm = T) # normalize weights to maintain sample size
chol.mod2 <- glm(T2DMcart.class~ firstage + factor(race) + gender + cholmean1yr, data = data1, weights = w.mod, family = "binomial")
summary(chol.mod2)

# Compare parameter estimates from the two models
cbind(chol.mod1$coef,chol.mod2$coef)

```

